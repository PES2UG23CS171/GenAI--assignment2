{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "693b9b15",
   "metadata": {},
   "source": [
    "# Unit 2 Assignment: Building a Mixture of Experts (MoE) Router\n",
    "\n",
    "**Name:** Dhrushaj Achar\n",
    "**SRN:** PES2UG23CS171\n",
    "**Class:** 6C CSE\n",
    "\n",
    "**Topic:** Advanced Architecture using Groq API\n",
    "**Tools:** Python, Groq API, Dotenv\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "Build a **Smart Customer Support Router** using a Mixture of Experts (MoE) architecture that routes user queries to specialized expert configurations (Technical, Billing, General) using LLM-based intent classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c606b",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ec23eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install groq python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af467f",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Initialize Groq Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f2815c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq client initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "print(\"Groq client initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a0547",
   "metadata": {},
   "source": [
    "## 3. Define Expert Configurations (`MODEL_CONFIG`)\n",
    "\n",
    "We define different \"experts\" by using different **System Prompts** while using the same base model (`llama-3.3-70b-versatile`). Each expert specializes in a different domain:\n",
    "\n",
    "- **Technical Expert** ‚Äî Rigorous, code-focused, and precise\n",
    "- **Billing Expert** ‚Äî Empathetic, financial-focused, and policy-driven\n",
    "- **General Expert** ‚Äî Fallback for casual chat\n",
    "- **Tool Expert** ‚Äî Handles data lookup requests (Bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf35bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert configurations loaded:\n",
      "  - Technical Expert (model: mixtral-8x7b-32768, temp: 0.7)\n",
      "  - Billing Expert (model: mixtral-8x7b-32768, temp: 0.7)\n",
      "  - General Expert (model: mixtral-8x7b-32768, temp: 0.7)\n",
      "  - Tool Expert (model: mixtral-8x7b-32768, temp: 0.7)\n"
     ]
    }
   ],
   "source": [
    "MODEL_CONFIG = {\n",
    "    \"technical\": {\n",
    "        \"model\": \"llama-3.3-70b-versatile\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"system_prompt\": (\n",
    "            \"You are a Senior Technical Support Engineer. You are rigorous, code-focused, \"\n",
    "            \"and precise. Your job is to diagnose bugs, provide exact code fixes, and explain \"\n",
    "            \"technical concepts clearly. Always provide code snippets when relevant. \"\n",
    "            \"Structure your responses with: 1) Problem Diagnosis, 2) Root Cause, 3) Solution/Fix. \"\n",
    "            \"Use proper formatting for code blocks.\"\n",
    "        )\n",
    "    },\n",
    "    \"billing\": {\n",
    "        \"model\": \"llama-3.3-70b-versatile\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"system_prompt\": (\n",
    "            \"You are a Billing & Accounts Support Specialist. You are empathetic, \"\n",
    "            \"financial-focused, and policy-driven. You handle refund requests, subscription \"\n",
    "            \"issues, payment disputes, and billing inquiries with care. Always acknowledge the \"\n",
    "            \"customer's frustration, reference relevant policies, and provide clear next steps. \"\n",
    "            \"Structure your responses with: 1) Acknowledgment, 2) Policy Reference, \"\n",
    "            \"3) Resolution Steps.\"\n",
    "        )\n",
    "    },\n",
    "    \"general\": {\n",
    "        \"model\": \"llama-3.3-70b-versatile\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"system_prompt\": (\n",
    "            \"You are a friendly and helpful General Support Assistant. You handle casual \"\n",
    "            \"conversations, general inquiries, and anything that doesn't fall under technical \"\n",
    "            \"or billing categories. Be warm, conversational, and helpful. If a query seems \"\n",
    "            \"technical or billing-related, gently guide the user to clarify.\"\n",
    "        )\n",
    "    },\n",
    "    \"tool\": {\n",
    "        \"model\": \"llama-3.3-70b-versatile\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"system_prompt\": (\n",
    "            \"You are a Data Lookup Assistant. You help users fetch real-time data such as \"\n",
    "            \"cryptocurrency prices, stock prices, weather data, and other live information. \"\n",
    "            \"When data is provided to you, present it clearly and concisely.\"\n",
    "        )\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Expert configurations loaded:\")\n",
    "for expert, config in MODEL_CONFIG.items():\n",
    "    print(f\"  - {expert.capitalize()} Expert (model: {config['model']}, temp: {config['temperature']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472fdfc7",
   "metadata": {},
   "source": [
    "## 4. Build the Router Function (`route_prompt`)\n",
    "\n",
    "The router is the **core** of the MoE architecture. It uses an LLM call with `temperature=0` (for deterministic, consistent classification) to classify user input into one of the expert categories.\n",
    "\n",
    "The router returns **only** the category name ‚Äî nothing else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba7f7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def route_prompt(user_input):\n",
    "    \"\"\"\n",
    "    Routes a user query to the appropriate expert category.\n",
    "    \n",
    "    Uses an LLM call with temperature=0 for deterministic classification.\n",
    "    \n",
    "    Args:\n",
    "        user_input (str): The user's query string.\n",
    "    \n",
    "    Returns:\n",
    "        str: The category name ‚Äî one of 'technical', 'billing', 'tool', or 'general'.\n",
    "    \"\"\"\n",
    "    \n",
    "    VALID_CATEGORIES = [\"technical\", \"billing\", \"tool\", \"general\"]\n",
    "    \n",
    "    routing_prompt = (\n",
    "        \"You are a precise intent classifier. Classify the following user message \"\n",
    "        \"into exactly ONE of these categories: [technical, billing, tool, general].\\n\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"- 'technical': Bug reports, code errors, programming questions, software issues.\\n\"\n",
    "        \"- 'billing': Refund requests, payment issues, subscription problems, charges.\\n\"\n",
    "        \"- 'tool': Requests for live/real-time data like prices (crypto, stocks), weather, etc.\\n\"\n",
    "        \"- 'general': Casual chat, greetings, or anything that doesn't fit above.\\n\\n\"\n",
    "        \"Return ONLY the single category word. No explanation, no punctuation, no extra text.\"\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": routing_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=10\n",
    "    )\n",
    "    \n",
    "    category = response.choices[0].message.content.strip().lower()\n",
    "    \n",
    "    # Validate the category; default to 'general' if unrecognized\n",
    "    if category not in VALID_CATEGORIES:\n",
    "        print(f\"  [Router Warning] Unrecognized category '{category}', defaulting to 'general'.\")\n",
    "        category = \"general\"\n",
    "    \n",
    "    return category\n",
    "\n",
    "print(\"Router function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc16bb",
   "metadata": {},
   "source": [
    "## 5. Bonus: Mock Tool Function for Data Fetching\n",
    "\n",
    "Before building the orchestrator, we define the mock tool function that simulates fetching live data (e.g., cryptocurrency prices). This is used when the router classifies a query as `tool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86dd9eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock tool functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def mock_fetch_price(asset_name):\n",
    "    \"\"\"\n",
    "    Simulates fetching real-time price data for an asset.\n",
    "    \n",
    "    Args:\n",
    "        asset_name (str): The name of the asset (e.g., 'bitcoin', 'ethereum').\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string with the mock price data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Mock database of asset prices\n",
    "    mock_prices = {\n",
    "        \"bitcoin\": {\"price\": \"$67,432.15\", \"change_24h\": \"+2.3%\", \"market_cap\": \"$1.32T\"},\n",
    "        \"ethereum\": {\"price\": \"$3,521.80\", \"change_24h\": \"+1.8%\", \"market_cap\": \"$423B\"},\n",
    "        \"solana\": {\"price\": \"$142.67\", \"change_24h\": \"-0.5%\", \"market_cap\": \"$63B\"},\n",
    "        \"dogecoin\": {\"price\": \"$0.1234\", \"change_24h\": \"+5.1%\", \"market_cap\": \"$17.6B\"},\n",
    "    }\n",
    "    \n",
    "    asset_key = asset_name.lower().strip()\n",
    "    \n",
    "    if asset_key in mock_prices:\n",
    "        data = mock_prices[asset_key]\n",
    "        return (\n",
    "            f\"üìä {asset_name.capitalize()} Price Data (Mock):\\n\"\n",
    "            f\"  Price: {data['price']}\\n\"\n",
    "            f\"  24h Change: {data['change_24h']}\\n\"\n",
    "            f\"  Market Cap: {data['market_cap']}\"\n",
    "        )\n",
    "    else:\n",
    "        return f\"‚ö†Ô∏è Sorry, price data for '{asset_name}' is not available in our mock database.\"\n",
    "\n",
    "\n",
    "def extract_asset_from_query(user_input):\n",
    "    \"\"\"\n",
    "    Extracts the asset name from a user's price query using simple keyword matching.\n",
    "    \"\"\"\n",
    "    known_assets = [\"bitcoin\", \"ethereum\", \"solana\", \"dogecoin\"]\n",
    "    user_lower = user_input.lower()\n",
    "    \n",
    "    for asset in known_assets:\n",
    "        if asset in user_lower:\n",
    "            return asset\n",
    "    \n",
    "    # If no known asset found, try to extract from common patterns\n",
    "    words = user_lower.split()\n",
    "    for i, word in enumerate(words):\n",
    "        if word in [\"of\", \"for\"] and i + 1 < len(words):\n",
    "            candidate = words[i + 1].strip(\"?.,!\")\n",
    "            return candidate\n",
    "    \n",
    "    return \"unknown\"\n",
    "\n",
    "print(\"Mock tool functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ebc886",
   "metadata": {},
   "source": [
    "## 6. Build the Orchestrator Function (`process_request`)\n",
    "\n",
    "The orchestrator ties everything together:\n",
    "1. Calls `route_prompt()` to classify the user's intent\n",
    "2. If the category is `tool`, calls the mock data-fetching function\n",
    "3. Otherwise, selects the correct expert's System Prompt and calls the LLM\n",
    "4. Returns the expert's response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9899b3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orchestrator function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def process_request(user_input):\n",
    "    \"\"\"\n",
    "    Main orchestrator function that processes a user request through the MoE pipeline.\n",
    "    \n",
    "    1. Routes the query to the appropriate expert category.\n",
    "    2. If 'tool', calls the mock data-fetching function.\n",
    "    3. Otherwise, calls the LLM with the expert's system prompt.\n",
    "    4. Returns the final response.\n",
    "    \n",
    "    Args:\n",
    "        user_input (str): The user's query string.\n",
    "    \n",
    "    Returns:\n",
    "        str: The expert's response.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üì® User Query: {user_input}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Step 1: Route the query\n",
    "    category = route_prompt(user_input)\n",
    "    print(f\"üîÄ Router Decision: '{category}' expert selected\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    \n",
    "    # Step 2: Handle tool requests (Bonus)\n",
    "    if category == \"tool\":\n",
    "        asset_name = extract_asset_from_query(user_input)\n",
    "        print(f\"üîß Tool Use: Fetching data for '{asset_name}'...\")\n",
    "        result = mock_fetch_price(asset_name)\n",
    "        print(f\"\\n{result}\")\n",
    "        return result\n",
    "    \n",
    "    # Step 3: Get the expert configuration\n",
    "    expert_config = MODEL_CONFIG.get(category, MODEL_CONFIG[\"general\"])\n",
    "    \n",
    "    # Step 4: Call the LLM with the expert's system prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=expert_config[\"model\"],\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": expert_config[\"system_prompt\"]},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ],\n",
    "        temperature=expert_config[\"temperature\"],\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    \n",
    "    expert_response = response.choices[0].message.content\n",
    "    \n",
    "    print(f\"ü§ñ {category.capitalize()} Expert Response:\\n\")\n",
    "    print(expert_response)\n",
    "    \n",
    "    return expert_response\n",
    "\n",
    "print(\"Orchestrator function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0722e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Testing the MoE Router\n",
    "\n",
    "### Test 1: Technical Query\n",
    "The router should classify this as **\"technical\"** and respond with code-focused debugging advice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f084fdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üì® User Query: My python script is throwing an IndexError on line 5.\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test 1: Technical Query\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m response = \u001b[43mprocess_request\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMy python script is throwing an IndexError on line 5.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mprocess_request\u001b[39m\u001b[34m(user_input)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Step 1: Route the query\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m category = \u001b[43mroute_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müîÄ Router Decision: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m expert selected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mroute_prompt\u001b[39m\u001b[34m(user_input)\u001b[39m\n\u001b[32m     14\u001b[39m VALID_CATEGORIES = [\u001b[33m\"\u001b[39m\u001b[33mtechnical\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbilling\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtool\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgeneral\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     16\u001b[39m routing_prompt = (\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mYou are a precise intent classifier. Classify the following user message \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minto exactly ONE of these categories: [technical, billing, tool, general].\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mReturn ONLY the single category word. No explanation, no punctuation, no extra text.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmixtral-8x7b-32768\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouting_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m     35\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m category = response.choices[\u001b[32m0\u001b[39m].message.content.strip().lower()\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Validate the category; default to 'general' if unrecognized\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/PES2UG23CS171/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py:461\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    242\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    243\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    300\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    301\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    302\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    303\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    304\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    459\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcitation_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcitation_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompound_custom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompound_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdisable_tool_validation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tool_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_reasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/PES2UG23CS171/.venv/lib/python3.12/site-packages/groq/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/PES2UG23CS171/.venv/lib/python3.12/site-packages/groq/_base_client.py:1044\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1041\u001b[39m             err.response.read()\n\u001b[32m   1043\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}"
     ]
    }
   ],
   "source": [
    "# Test 1: Technical Query\n",
    "response = process_request(\"My python script is throwing an IndexError on line 5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349afd9b",
   "metadata": {},
   "source": [
    "### Test 2: Billing Query\n",
    "The router should classify this as **\"billing\"** and respond with empathetic, policy-driven support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39450339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Billing Query\n",
    "response = process_request(\"I was charged twice for my subscription this month.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a981149",
   "metadata": {},
   "source": [
    "### Test 3: General Query\n",
    "The router should classify this as **\"general\"** and respond with friendly casual conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f776ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Query\n",
    "response = process_request(\"Hey, how are you doing today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f0226",
   "metadata": {},
   "source": [
    "### Test 4: Bonus ‚Äî Tool Use Expert (Bitcoin Price Query)\n",
    "The router should classify this as **\"tool\"** and return mock-fetched Bitcoin price data instead of an LLM-generated response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Bonus - Tool Use Expert (Bitcoin Price)\n",
    "response = process_request(\"What is the current price of Bitcoin?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
